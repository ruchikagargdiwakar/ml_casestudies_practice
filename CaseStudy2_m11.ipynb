{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from “glass.csv” and make a bar plot of different types of glasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"glass.csv\")\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  counts\n",
       "0     1      70\n",
       "1     2      76\n",
       "2     3      17\n",
       "3     5      13\n",
       "4     6       9\n",
       "5     7      29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#df.groupby('Type').agg(['mean', 'count'])\n",
    "df_new = df.groupby('Type').size().reset_index(name='counts')\n",
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_label = df_new['Type']\n",
    "plt_benefitted_inmates = df_new['counts']\n",
    "\n",
    "def plot_bar_x():\n",
    "    index = np.arange(len(plt_label))\n",
    "    plt.bar(index, plt_benefitted_inmates)\n",
    "    plt.xlabel('Type', fontsize=10)\n",
    "    plt.ylabel('Counts', fontsize=10)\n",
    "    plt.xticks(index, plt_label, fontsize=10, rotation=90)\n",
    "    plt.title('Counts for each glass type')\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_x()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a train_test split and fit a single decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df, df['Type'], test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "lda.fit(train_x, train_y)\n",
    "train_x = lda.transform(train_x)\n",
    "test_x = lda.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.51743</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.14</td>\n",
       "      <td>73.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.51756</td>\n",
       "      <td>13.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.51918</td>\n",
       "      <td>14.04</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.51571</td>\n",
       "      <td>12.72</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.56</td>\n",
       "      <td>73.20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.51763</td>\n",
       "      <td>12.80</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.27</td>\n",
       "      <td>73.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.51589</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.40</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.51748</td>\n",
       "      <td>12.86</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.27</td>\n",
       "      <td>73.21</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.51763</td>\n",
       "      <td>12.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.31</td>\n",
       "      <td>73.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.23</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.51784</td>\n",
       "      <td>12.68</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.16</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.52196</td>\n",
       "      <td>14.36</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.51911</td>\n",
       "      <td>13.90</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.18</td>\n",
       "      <td>72.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.51735</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.69</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.51750</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.49</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51736</td>\n",
       "      <td>12.78</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.51751</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.35</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.51720</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>72.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.51764</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.21</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.51793</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.51721</td>\n",
       "      <td>12.87</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.33</td>\n",
       "      <td>73.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.51768</td>\n",
       "      <td>12.56</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.43</td>\n",
       "      <td>73.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.51784</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.28</td>\n",
       "      <td>72.86</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51131</td>\n",
       "      <td>13.69</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.81</td>\n",
       "      <td>72.81</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.51838</td>\n",
       "      <td>14.32</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.22</td>\n",
       "      <td>71.25</td>\n",
       "      <td>1.46</td>\n",
       "      <td>5.79</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.52315</td>\n",
       "      <td>13.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.23</td>\n",
       "      <td>72.38</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.52247</td>\n",
       "      <td>14.86</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.06</td>\n",
       "      <td>70.26</td>\n",
       "      <td>0.76</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.52365</td>\n",
       "      <td>15.79</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.31</td>\n",
       "      <td>70.43</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.51613</td>\n",
       "      <td>13.88</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.79</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.51602</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>73.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.51719</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.53</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.51683</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>73.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.52</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.51545</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>73.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.07</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.51556</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.54</td>\n",
       "      <td>73.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.41</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.51727</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.51531</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.66</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.51609</td>\n",
       "      <td>15.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.51</td>\n",
       "      <td>73.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.51508</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>73.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.34</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.51653</td>\n",
       "      <td>11.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>75.18</td>\n",
       "      <td>2.70</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.51514</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>73.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.51658</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1.51617</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.51732</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1.51645</td>\n",
       "      <td>14.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1.51831</td>\n",
       "      <td>14.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>72.86</td>\n",
       "      <td>1.41</td>\n",
       "      <td>6.47</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1.51640</td>\n",
       "      <td>14.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>72.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba    Fe\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.00\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00\n",
       "5    1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26\n",
       "6    1.51743  13.30  3.60  1.14  73.09  0.58  8.17  0.00  0.00\n",
       "7    1.51756  13.15  3.61  1.05  73.24  0.57  8.24  0.00  0.00\n",
       "8    1.51918  14.04  3.58  1.37  72.08  0.56  8.30  0.00  0.00\n",
       "9    1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.00  0.11\n",
       "10   1.51571  12.72  3.46  1.56  73.20  0.67  8.09  0.00  0.24\n",
       "11   1.51763  12.80  3.66  1.27  73.01  0.60  8.56  0.00  0.00\n",
       "12   1.51589  12.88  3.43  1.40  73.28  0.69  8.05  0.00  0.24\n",
       "13   1.51748  12.86  3.56  1.27  73.21  0.54  8.38  0.00  0.17\n",
       "14   1.51763  12.61  3.59  1.31  73.29  0.58  8.50  0.00  0.00\n",
       "15   1.51761  12.81  3.54  1.23  73.24  0.58  8.39  0.00  0.00\n",
       "16   1.51784  12.68  3.67  1.16  73.11  0.61  8.70  0.00  0.00\n",
       "17   1.52196  14.36  3.85  0.89  71.36  0.15  9.15  0.00  0.00\n",
       "18   1.51911  13.90  3.73  1.18  72.12  0.06  8.89  0.00  0.00\n",
       "19   1.51735  13.02  3.54  1.69  72.73  0.54  8.44  0.00  0.07\n",
       "20   1.51750  12.82  3.55  1.49  72.75  0.54  8.52  0.00  0.19\n",
       "21   1.51966  14.77  3.75  0.29  72.02  0.03  9.00  0.00  0.00\n",
       "22   1.51736  12.78  3.62  1.29  72.79  0.59  8.70  0.00  0.00\n",
       "23   1.51751  12.81  3.57  1.35  73.02  0.62  8.59  0.00  0.00\n",
       "24   1.51720  13.38  3.50  1.15  72.85  0.50  8.43  0.00  0.00\n",
       "25   1.51764  12.98  3.54  1.21  73.00  0.65  8.53  0.00  0.00\n",
       "26   1.51793  13.21  3.48  1.41  72.64  0.59  8.43  0.00  0.00\n",
       "27   1.51721  12.87  3.48  1.33  73.04  0.56  8.43  0.00  0.00\n",
       "28   1.51768  12.56  3.52  1.43  73.15  0.57  8.54  0.00  0.00\n",
       "29   1.51784  13.08  3.49  1.28  72.86  0.60  8.49  0.00  0.00\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...   ...\n",
       "184  1.51115  17.38  0.00  0.34  75.41  0.00  6.65  0.00  0.00\n",
       "185  1.51131  13.69  3.20  1.81  72.81  1.76  5.43  1.19  0.00\n",
       "186  1.51838  14.32  3.26  2.22  71.25  1.46  5.79  1.63  0.00\n",
       "187  1.52315  13.44  3.34  1.23  72.38  0.60  8.83  0.00  0.00\n",
       "188  1.52247  14.86  2.20  2.06  70.26  0.76  9.76  0.00  0.00\n",
       "189  1.52365  15.79  1.83  1.31  70.43  0.31  8.61  1.68  0.00\n",
       "190  1.51613  13.88  1.78  1.79  73.10  0.00  8.67  0.76  0.00\n",
       "191  1.51602  14.85  0.00  2.38  73.28  0.00  8.76  0.64  0.09\n",
       "192  1.51623  14.20  0.00  2.79  73.46  0.04  9.04  0.40  0.09\n",
       "193  1.51719  14.75  0.00  2.00  73.02  0.00  8.53  1.59  0.08\n",
       "194  1.51683  14.56  0.00  1.98  73.29  0.00  8.52  1.57  0.07\n",
       "195  1.51545  14.14  0.00  2.68  73.39  0.08  9.07  0.61  0.05\n",
       "196  1.51556  13.87  0.00  2.54  73.23  0.14  9.41  0.81  0.01\n",
       "197  1.51727  14.70  0.00  2.34  73.28  0.00  8.95  0.66  0.00\n",
       "198  1.51531  14.38  0.00  2.66  73.10  0.04  9.08  0.64  0.00\n",
       "199  1.51609  15.01  0.00  2.51  73.05  0.05  8.83  0.53  0.00\n",
       "200  1.51508  15.15  0.00  2.25  73.50  0.00  8.34  0.63  0.00\n",
       "201  1.51653  11.95  0.00  1.19  75.18  2.70  8.93  0.00  0.00\n",
       "202  1.51514  14.85  0.00  2.42  73.72  0.00  8.39  0.56  0.00\n",
       "203  1.51658  14.80  0.00  1.99  73.11  0.00  8.28  1.71  0.00\n",
       "204  1.51617  14.95  0.00  2.27  73.30  0.00  8.71  0.67  0.00\n",
       "205  1.51732  14.95  0.00  1.80  72.99  0.00  8.61  1.55  0.00\n",
       "206  1.51645  14.94  0.00  1.87  73.11  0.00  8.67  1.38  0.00\n",
       "207  1.51831  14.39  0.00  1.82  72.86  1.41  6.47  2.88  0.00\n",
       "208  1.51640  14.37  0.00  2.74  72.85  0.00  9.45  0.54  0.00\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00\n",
       "\n",
       "[214 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Accuracy of model:: 0.013888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "classifiers = [DecisionTreeClassifier()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    name = clf.__class__.__name__\n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    clf.fit(train_x,train_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "    #calculate accuracy\n",
    "    calc_accuracy = metrics.accuracy_score(test_y,pred_y)\n",
    "    print(\"Accuracy of model::\", calc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a k-fold split with 3 splits and measure the accuracy score with each split[Hint:Refer to KFold module under sklearn’s model selection.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "TRAIN: [ 72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "Accuracy of model:: 0.013888888888888888\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213] TEST: [ 72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142]\n",
      "Accuracy of model:: 0.16901408450704225\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142] TEST: [143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213]\n",
      "Accuracy of model:: 0.028169014084507043\n",
      "Av Accuracy of model:: 0.07035732916014606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(df)\n",
    "print(kf)\n",
    "df_x = df.iloc[:,:9]\n",
    "df_y = df['Type']\n",
    "x = df_x.values\n",
    "y = df_y.values\n",
    "\n",
    "sum = 0.0\n",
    "\n",
    "KFold(n_splits=3, random_state=None, shuffle=False)\n",
    "for train_index, test_index in kf.split(df):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_x, test_x = x[train_index], x[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    clf.fit(train_x,train_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "    #calculate accuracy\n",
    "    calc_accuracy = metrics.accuracy_score(test_y,pred_y)\n",
    "    print(\"Accuracy of model::\", calc_accuracy)\n",
    "    sum = sum + calc_accuracy\n",
    "print(\"Av Accuracy of model::\", sum/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use gridSearchCV from sklearn for finding out a suitable number of estimators for a RandomForestClassifer alongwith a 10-fold cross validation.[Hint:Define a range of estimators and feed in range as param_grid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56521739 0.56521739 0.7826087  0.59090909 0.54545455 0.95454545\n",
      " 0.85714286 0.45       0.75       0.66666667]\n",
      "Average score:: 0.6727762092979485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x = df.iloc[:,:9]\n",
    "y = df['Type']\n",
    "scores_sum = 0.0\n",
    "\n",
    "parameters = {'max_depth':range(3,20)}\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, n_jobs=4)\n",
    "\n",
    "scores = cross_val_score(estimator=clf, X=x, y=y, cv=10, n_jobs=4)\n",
    "print (scores) \n",
    "for scr in scores:\n",
    "    scores_sum = scores_sum + scr\n",
    "print(\"Average score::\", scores_sum/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
