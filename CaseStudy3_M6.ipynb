{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from “college.csv” that has attributes collected about private and public colleges for a particular year. We will try to predict the private/public status of the college from other attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes</td>\n",
       "      <td>587</td>\n",
       "      <td>479</td>\n",
       "      <td>158</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>678</td>\n",
       "      <td>41</td>\n",
       "      <td>13500</td>\n",
       "      <td>3335</td>\n",
       "      <td>500</td>\n",
       "      <td>675</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11</td>\n",
       "      <td>9727</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes</td>\n",
       "      <td>353</td>\n",
       "      <td>340</td>\n",
       "      <td>103</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>416</td>\n",
       "      <td>230</td>\n",
       "      <td>13290</td>\n",
       "      <td>5720</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>11.5</td>\n",
       "      <td>26</td>\n",
       "      <td>8861</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1899</td>\n",
       "      <td>1720</td>\n",
       "      <td>489</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>1594</td>\n",
       "      <td>32</td>\n",
       "      <td>13868</td>\n",
       "      <td>4826</td>\n",
       "      <td>450</td>\n",
       "      <td>850</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>13.7</td>\n",
       "      <td>37</td>\n",
       "      <td>11487</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1038</td>\n",
       "      <td>839</td>\n",
       "      <td>227</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>973</td>\n",
       "      <td>306</td>\n",
       "      <td>15595</td>\n",
       "      <td>4400</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>11.3</td>\n",
       "      <td>23</td>\n",
       "      <td>11644</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes</td>\n",
       "      <td>582</td>\n",
       "      <td>498</td>\n",
       "      <td>172</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>799</td>\n",
       "      <td>78</td>\n",
       "      <td>10468</td>\n",
       "      <td>3380</td>\n",
       "      <td>660</td>\n",
       "      <td>1800</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15</td>\n",
       "      <td>8991</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1732</td>\n",
       "      <td>1425</td>\n",
       "      <td>472</td>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>1830</td>\n",
       "      <td>110</td>\n",
       "      <td>16548</td>\n",
       "      <td>5406</td>\n",
       "      <td>500</td>\n",
       "      <td>600</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>11.3</td>\n",
       "      <td>31</td>\n",
       "      <td>10932</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2652</td>\n",
       "      <td>1900</td>\n",
       "      <td>484</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>1707</td>\n",
       "      <td>44</td>\n",
       "      <td>17080</td>\n",
       "      <td>4440</td>\n",
       "      <td>400</td>\n",
       "      <td>600</td>\n",
       "      <td>73</td>\n",
       "      <td>91</td>\n",
       "      <td>9.9</td>\n",
       "      <td>41</td>\n",
       "      <td>11711</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1179</td>\n",
       "      <td>780</td>\n",
       "      <td>290</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>1130</td>\n",
       "      <td>638</td>\n",
       "      <td>9690</td>\n",
       "      <td>4785</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>13.3</td>\n",
       "      <td>21</td>\n",
       "      <td>7940</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1267</td>\n",
       "      <td>1080</td>\n",
       "      <td>385</td>\n",
       "      <td>44</td>\n",
       "      <td>73</td>\n",
       "      <td>1306</td>\n",
       "      <td>28</td>\n",
       "      <td>12572</td>\n",
       "      <td>4552</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>15.3</td>\n",
       "      <td>32</td>\n",
       "      <td>9305</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yes</td>\n",
       "      <td>494</td>\n",
       "      <td>313</td>\n",
       "      <td>157</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>1317</td>\n",
       "      <td>1235</td>\n",
       "      <td>8352</td>\n",
       "      <td>3640</td>\n",
       "      <td>650</td>\n",
       "      <td>2449</td>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>11.1</td>\n",
       "      <td>26</td>\n",
       "      <td>8127</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1420</td>\n",
       "      <td>1093</td>\n",
       "      <td>220</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>1018</td>\n",
       "      <td>287</td>\n",
       "      <td>8700</td>\n",
       "      <td>4780</td>\n",
       "      <td>450</td>\n",
       "      <td>1400</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>14.7</td>\n",
       "      <td>19</td>\n",
       "      <td>7355</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yes</td>\n",
       "      <td>4302</td>\n",
       "      <td>992</td>\n",
       "      <td>418</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>1593</td>\n",
       "      <td>5</td>\n",
       "      <td>19760</td>\n",
       "      <td>5300</td>\n",
       "      <td>660</td>\n",
       "      <td>1598</td>\n",
       "      <td>93</td>\n",
       "      <td>98</td>\n",
       "      <td>8.4</td>\n",
       "      <td>63</td>\n",
       "      <td>21424</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1216</td>\n",
       "      <td>908</td>\n",
       "      <td>423</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>1819</td>\n",
       "      <td>281</td>\n",
       "      <td>10100</td>\n",
       "      <td>3520</td>\n",
       "      <td>550</td>\n",
       "      <td>1100</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14</td>\n",
       "      <td>7994</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1130</td>\n",
       "      <td>704</td>\n",
       "      <td>322</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>1586</td>\n",
       "      <td>326</td>\n",
       "      <td>9996</td>\n",
       "      <td>3090</td>\n",
       "      <td>900</td>\n",
       "      <td>1320</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>11.5</td>\n",
       "      <td>18</td>\n",
       "      <td>10908</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>No</td>\n",
       "      <td>3540</td>\n",
       "      <td>2001</td>\n",
       "      <td>1016</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>4190</td>\n",
       "      <td>1512</td>\n",
       "      <td>5130</td>\n",
       "      <td>3592</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5</td>\n",
       "      <td>4010</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0      Yes  1660    1232     721         23         52         2885   \n",
       "1      Yes  2186    1924     512         16         29         2683   \n",
       "2      Yes  1428    1097     336         22         50         1036   \n",
       "3      Yes   417     349     137         60         89          510   \n",
       "4      Yes   193     146      55         16         44          249   \n",
       "5      Yes   587     479     158         38         62          678   \n",
       "6      Yes   353     340     103         17         45          416   \n",
       "7      Yes  1899    1720     489         37         68         1594   \n",
       "8      Yes  1038     839     227         30         63          973   \n",
       "9      Yes   582     498     172         21         44          799   \n",
       "10     Yes  1732    1425     472         37         75         1830   \n",
       "11     Yes  2652    1900     484         44         77         1707   \n",
       "12     Yes  1179     780     290         38         64         1130   \n",
       "13     Yes  1267    1080     385         44         73         1306   \n",
       "14     Yes   494     313     157         23         46         1317   \n",
       "15     Yes  1420    1093     220          9         22         1018   \n",
       "16     Yes  4302     992     418         83         96         1593   \n",
       "17     Yes  1216     908     423         19         40         1819   \n",
       "18     Yes  1130     704     322         14         23         1586   \n",
       "19      No  3540    2001    1016         24         54         4190   \n",
       "\n",
       "    P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0           537      7440        3300    450      2200   70        78   \n",
       "1          1227     12280        6450    750      1500   29        30   \n",
       "2            99     11250        3750    400      1165   53        66   \n",
       "3            63     12960        5450    450       875   92        97   \n",
       "4           869      7560        4120    800      1500   76        72   \n",
       "5            41     13500        3335    500       675   67        73   \n",
       "6           230     13290        5720    500      1500   90        93   \n",
       "7            32     13868        4826    450       850   89       100   \n",
       "8           306     15595        4400    300       500   79        84   \n",
       "9            78     10468        3380    660      1800   40        41   \n",
       "10          110     16548        5406    500       600   82        88   \n",
       "11           44     17080        4440    400       600   73        91   \n",
       "12          638      9690        4785    600      1000   60        84   \n",
       "13           28     12572        4552    400       400   79        87   \n",
       "14         1235      8352        3640    650      2449   36        69   \n",
       "15          287      8700        4780    450      1400   78        84   \n",
       "16            5     19760        5300    660      1598   93        98   \n",
       "17          281     10100        3520    550      1100   48        61   \n",
       "18          326      9996        3090    900      1320   62        66   \n",
       "19         1512      5130        3592    500      2000   60        62   \n",
       "\n",
       "    S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0        18.1           12    7041         60  \n",
       "1        12.2           16   10527         56  \n",
       "2        12.9           30    8735         54  \n",
       "3         7.7           37   19016         59  \n",
       "4        11.9            2   10922         15  \n",
       "5         9.4           11    9727         55  \n",
       "6        11.5           26    8861         63  \n",
       "7        13.7           37   11487         73  \n",
       "8        11.3           23   11644         80  \n",
       "9        11.5           15    8991         52  \n",
       "10       11.3           31   10932         73  \n",
       "11        9.9           41   11711         76  \n",
       "12       13.3           21    7940         74  \n",
       "13       15.3           32    9305         68  \n",
       "14       11.1           26    8127         55  \n",
       "15       14.7           19    7355         69  \n",
       "16        8.4           63   21424        100  \n",
       "17       12.1           14    7994         59  \n",
       "18       11.5           18   10908         46  \n",
       "19       23.1            5    4010         34  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"college.csv\")\n",
    "#df1 = df.copy\n",
    "#df2 = df.copy\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LabelEncoder to encode the target variable in to numerical form and split the data such that 20% of the data is set aside fortesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#data preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df['Private'])\n",
    "le.classes_\n",
    "df['Private'] = le.transform(df['Private'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df.iloc[:,2:], df['Private'], test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a linear svm from scikit learn and observe the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy:: 0.7115384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(train_x, train_y)\n",
    "pred_y = model.predict(test_x)\n",
    "\n",
    "print(\"SVM accuracy::\", accuracy_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data using StandardScalar and fit the same model again and observe the change in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy:: 0.7115384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#data preprocessing\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(df)\n",
    "scalar.transform(df)\n",
    "\n",
    "#train_ss_x, test_ss_x, train_ss_y, test_ss_y = train_test_split(df.iloc[:,2:], df['Private'], test_size=0.20, random_state=5)\n",
    "model1 = svm.SVC()\n",
    "model1.fit(train_x, train_y)\n",
    "pred_ss_y = model1.predict(test_x)\n",
    "\n",
    "print(\"SVM accuracy::\", accuracy_score(test_y, pred_ss_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use scikit learn’s gridsearch to select the best hyperparameter for a non-linear SVM,identify the model with best score and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruchika_garg01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
      "SVM accuracy:: 0.7115384615384616\n",
      "The best parameters are {'C': 0.1, 'gamma': 1} with a score of 0.73::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#data preprocessing\n",
    "param_grid = {'C':[0.1,1,10,100],'gamma':[1,0.1,0.01,0.001]}\n",
    "\n",
    "#train_gscv_x, test_gscv_x, train_gscv_y, test_gscv_y = train_test_split(df.iloc[:,2:], df['Private'], test_size=0.20, random_state=5)\n",
    "\n",
    "gscv = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose = 2)\n",
    "gscv.fit(train_x,train_y)\n",
    "\n",
    "pred_gscv_y = model1.predict(test_x)\n",
    "\n",
    "print(\"SVM accuracy::\", accuracy_score(test_y, pred_gscv_y))\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(gscv.best_params_, gscv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
